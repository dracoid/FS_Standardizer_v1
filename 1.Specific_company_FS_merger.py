# main_specific_company.py
import pandas as pd
import os
from glob import glob
from datetime import datetime

from FS_Deduplicator import preprocess_financial_data
from FS_standardizer_IS.standardizer import standardize_income_statement
from FS_standardizer_BS.standardizer import standardize_balance_sheet


def run_fs_standardization():
    # Step 1: ì‚¬ìš©ì ì…ë ¥
    ticker = input("Enter the ticker symbol: ").upper().strip()

    # Step 2: ë§¤í•‘ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
    mapper_path = "/Volumes/SSD1TB/30.Financial_data_python/SEC_data_SIC_ticker/ticker_mapper.parquet"
    mapper_df = pd.read_parquet(mapper_path)

    if ticker not in mapper_df['ticker'].values:
        raise ValueError(f"âŒ {ticker} not found in ticker_mapper.parquet")

    target_path = mapper_df.loc[mapper_df['ticker'] == ticker, 'FS_Path'].values[0]
    cik = mapper_df.loc[mapper_df['ticker'] == ticker, 'cik'].values[0]
    sic = mapper_df.loc[mapper_df['ticker'] == ticker, 'sic'].values[0]

    if not os.path.exists(target_path):
        raise FileNotFoundError(f"âŒ Target path does not exist: {target_path}")
    print(f"âœ” Ticker {ticker} is mapped to path: {target_path}")

    # Step 3: íŒŒì¼ ë³‘í•©
    parquet_files = sorted(glob(os.path.join(target_path, "*.parquet")))
    if not parquet_files:
        raise FileNotFoundError("âŒ No parquet files found in the target directory.")

    dfs = [pd.read_parquet(pf) for pf in parquet_files]
    merged_df = pd.concat(dfs, ignore_index=True)
    print(f"âœ” Merged {len(parquet_files)} files with total {len(merged_df)} rows")

    # Step 4: ê³µí†µ ì „ì²˜ë¦¬
    cleaned_df = preprocess_financial_data(merged_df)
    cleaned_df["segments"] = cleaned_df["segments"].fillna("[Total]")

    # Step 5: IS / BS í‘œì¤€í™”
    is_df = standardize_income_statement(cleaned_df, default_sic=sic)
    bs_df = standardize_balance_sheet(cleaned_df, default_sic=sic)

    # Step 6: ë‚˜ë¨¸ì§€ stmt êµ¬ë¶„
    known_stmts = ["IS", "BS"]
    other_df = cleaned_df[~cleaned_df["stmt"].str.upper().isin(known_stmts)].copy()

    # Step 7: ì „ì²´ ë³‘í•© ë° ì •ë ¬
    final_df = pd.concat([is_df, bs_df, other_df], ignore_index=True)
    final_df.sort_values("ddate_label_month", inplace=True)

    # Step 8: ì €ì¥ ê²½ë¡œ ì„¤ì •
    output_dir = "/Volumes/SSD1TB/30.Financial_data_python/CompanyAnalysis"
    os.makedirs(output_dir, exist_ok=True)
    today_str = datetime.today().strftime("%y-%m-%d")
    base_name = f"{ticker}_{today_str}"

    # Step 9: ì „ì²´ íŒŒì¼ ì €ì¥
    final_parquet = os.path.join(output_dir, f"{base_name}.parquet")
    final_excel = os.path.join(output_dir, f"{base_name}.xlsx")
    final_df.to_parquet(final_parquet, index=False)
    final_df.to_excel(final_excel, index=False)
    print(f"\nğŸ“ Full FS saved to:\n  - {final_parquet}\n  - {final_excel}")

    # Step 10: stmtë³„ ë¶„ë¦¬ ì €ì¥
    for stmt_type in final_df['stmt'].dropna().unique():
        stmt_df = final_df[final_df['stmt'].str.upper() == stmt_type.upper()].copy()
        if stmt_df.empty:
            continue

        stmt_excel = os.path.join(output_dir, f"{base_name}_{stmt_type.upper()}.xlsx")
        stmt_df.to_excel(stmt_excel, index=False)

        print(f"ğŸ“„ Saved {stmt_type.upper()} to:\n  - {stmt_excel}\n ")


if __name__ == "__main__":
    run_fs_standardization()
